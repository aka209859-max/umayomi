# UMAYOMI Phase 4A: JRDBãƒ‡ãƒ¼ã‚¿çµ±åˆå®Ÿè£…ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ

## ğŸ¯ å®Ÿè£…ç›®çš„
ç«¶é¦¬äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ã€ŒUMAYOMIã€ã®ãƒ‡ãƒ¼ã‚¿åŸºç›¤ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚CEOã®ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã«æ—¢ã«å­˜åœ¨ã™ã‚‹JRDBãƒ‡ãƒ¼ã‚¿ï¼ˆ18,974ãƒ•ã‚¡ã‚¤ãƒ«ã€3.87GBã€2014-2025å¹´ï¼‰ã‚’PostgreSQLã¸æŠ•å…¥ã—ã€ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ä½œæˆã‚·ã‚¹ãƒ†ãƒ ã®ææ–™åº«ã‚’å®Œæˆã•ã›ã‚‹ã€‚

---

## ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ã®å ´æ‰€ï¼ˆå®Œå…¨ç‰¹å®šæ¸ˆã¿ï¼‰

### ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹
```
C:\JRDB\unzipped\
```

### ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ
- **KYI*.txt**: 1,265ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆé¦¬ãƒ‡ãƒ¼ã‚¿ã€è¹„ã‚³ãƒ¼ãƒ‰ 164-165ãƒã‚¤ãƒˆç›®ï¼‰
- **ZKB*.txt**: 1,265ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæˆç¸¾æ‹¡å¼µã€è¹„é‰„ 280-282ãƒã‚¤ãƒˆç›®ã€è¹„çŠ¶æ…‹ 283-285ãƒã‚¤ãƒˆç›®ï¼‰
- **CYB*.txt**: 1,265ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆèª¿æ•™ãƒ‡ãƒ¼ã‚¿ï¼‰
- **ZED*.txt**: 1,265ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ¬ãƒ¼ã‚¹åŸºæœ¬æƒ…å ±ï¼‰
- **BAC*.txt**: 1,265ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆé¦¬åŸºæœ¬æƒ…å ±ï¼‰
- **CHA*.txt**: 1,265ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆèª¿æ•™å¸«ãƒ‡ãƒ¼ã‚¿ï¼‰
- **JOA*.txt**: 1,265ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆé¨æ‰‹ãƒ‡ãƒ¼ã‚¿ï¼‰
- **KAB*.txt**: 1,265ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆé–‹å‚¬å ´æƒ…å ±ï¼‰
- **KKA*.txt**: 1,265ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆé¦¬åŸºæœ¬æƒ…å ±ï¼‰
- **UKC*.txt**: 1,265ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆé¦¬æˆç¸¾ï¼‰
- **OT1*.txt / OT2*.txt**: 1,265ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå˜å‹ã‚ªãƒƒã‚ºï¼‰
- **OU1*.txt / OU2*.txt**: 1,265ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆè¤‡å‹ã‚ªãƒƒã‚ºï¼‰
- **OW1*.txt / OW2*.txt**: 1,265ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ¯ã‚¤ãƒ‰ã‚ªãƒƒã‚ºï¼‰
- **OZ1*.txt / OZ2*.txt**: 1,265ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆé¦¬é€£ã‚ªãƒƒã‚ºï¼‰

**åˆè¨ˆ**: 18,974ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ3.87GBï¼‰  
**æœŸé–“**: 2014-01-05 ï½ 2025-08-24ï¼ˆ11å¹´8ãƒ¶æœˆï¼‰

### ãƒ•ã‚¡ã‚¤ãƒ«åè¦å‰‡
```
å½¢å¼: [TYPE][YYMMDD].txt

ä¾‹:
- KYI140105.txt â†’ 2014å¹´01æœˆ05æ—¥ã®KYIãƒ‡ãƒ¼ã‚¿
- ZKB250824.txt â†’ 2025å¹´08æœˆ24æ—¥ã®ZKBãƒ‡ãƒ¼ã‚¿

YY: å¹´ï¼ˆè¥¿æš¦ä¸‹2æ¡ï¼‰
MM: æœˆï¼ˆ01-12ï¼‰
DD: æ—¥ï¼ˆ01-31ï¼‰
```

### ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
- **Shift_JISï¼ˆCP932ï¼‰**
- å›ºå®šé•·ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
- è¡Œæœ«: CR+LFï¼ˆ2ãƒã‚¤ãƒˆï¼‰

---

## ğŸ“‹ å®Ÿè£…ã‚¿ã‚¹ã‚¯

### Phase 4A-1: ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹æ¤œè¨¼ã¨ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆä½œæˆ âœ…

**çŠ¶æ…‹**: å®Œäº†ï¼ˆPowerShellèª¿æŸ»æ¸ˆã¿ï¼‰

**çµæœ**:
- âœ… C:\JRDB\unzipped\ ã«ãƒ‡ãƒ¼ã‚¿å­˜åœ¨ç¢ºèª
- âœ… 18,974ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
- âœ… KYIè¹„ã‚³ãƒ¼ãƒ‰æŠ½å‡ºæ¤œè¨¼ï¼ˆ164-165ãƒã‚¤ãƒˆç›®ï¼‰
- âœ… æœ€å¤ãƒ•ã‚¡ã‚¤ãƒ«: BAC140105.txt (2014-01-05)
- âœ… æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«: ZKB250824.txt (2025-08-24)

---

### Phase 4A-2: KYIè¹„ã‚³ãƒ¼ãƒ‰æŠ½å‡ºã‚¹ã‚¯ãƒªãƒ—ãƒˆä½œæˆ

**ç›®çš„**: å…¨1,265ä»¶ã®KYIãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¹„ã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡º

**å…¥åŠ›**:
```
C:\JRDB\unzipped\KYI*.txtï¼ˆ1,265ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
```

**å‡¦ç†**:
```python
import os
import json
from datetime import datetime

def parse_kyi_hoof_code(file_path):
    """
    KYIãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¹„ã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡º
    
    ä»•æ§˜:
    - ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°: Shift_JIS
    - å›ºå®šé•·: 1024ãƒã‚¤ãƒˆ/ãƒ¬ã‚³ãƒ¼ãƒ‰
    - è¹„ã‚³ãƒ¼ãƒ‰ä½ç½®: 164-165ãƒã‚¤ãƒˆç›®ï¼ˆ0èµ·ç‚¹: 163-164ï¼‰
    """
    results = []
    
    with open(file_path, 'r', encoding='shift_jis', errors='ignore') as f:
        for line_num, line in enumerate(f, 1):
            try:
                # Shift_JISãƒã‚¤ãƒˆåˆ—ã¨ã—ã¦å‡¦ç†
                line_bytes = line.encode('shift_jis')
                
                # ãƒ¬ãƒ¼ã‚¹ã‚­ãƒ¼ï¼ˆ1-8ãƒã‚¤ãƒˆç›®ï¼‰
                race_key = line_bytes[0:8].decode('shift_jis').strip()
                
                # é¦¬ç•ªï¼ˆ9-10ãƒã‚¤ãƒˆç›®ï¼‰
                horse_number = line_bytes[8:10].decode('shift_jis').strip()
                
                # è¹„ã‚³ãƒ¼ãƒ‰ï¼ˆ164-165ãƒã‚¤ãƒˆç›®ã€0èµ·ç‚¹: 163-164ï¼‰
                hoof_code = line_bytes[163:165].decode('shift_jis').strip()
                
                # ç©ºç™½ã‚„NULLå€¤ã‚’ã‚¹ã‚­ãƒƒãƒ—
                if hoof_code and hoof_code != '  ':
                    results.append({
                        'race_key': race_key,
                        'horse_number': int(horse_number) if horse_number.isdigit() else None,
                        'hoof_code': hoof_code,
                        'line_number': line_num
                    })
                    
            except Exception as e:
                print(f"è­¦å‘Š: {file_path} è¡Œ{line_num}: {str(e)}")
                continue
    
    return results

def batch_process_kyi(data_dir, output_file):
    """
    å…¨KYIãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬å‡¦ç†
    """
    import glob
    
    all_results = []
    file_pattern = os.path.join(data_dir, 'KYI*.txt')
    kyi_files = sorted(glob.glob(file_pattern))
    
    print(f"KYIãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(kyi_files)}")
    
    for i, kyi_file in enumerate(kyi_files, 1):
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ—¥ä»˜ã‚’æŠ½å‡ºï¼ˆä¾‹: KYI140105.txt â†’ 2014-01-05ï¼‰
        filename = os.path.basename(kyi_file)
        date_str = filename[3:9]  # YYMMDD
        year = int('20' + date_str[0:2])
        month = int(date_str[2:4])
        day = int(date_str[4:6])
        file_date = f"{year:04d}-{month:02d}-{day:02d}"
        
        print(f"[{i}/{len(kyi_files)}] å‡¦ç†ä¸­: {filename} ({file_date})")
        
        # è¹„ã‚³ãƒ¼ãƒ‰æŠ½å‡º
        records = parse_kyi_hoof_code(kyi_file)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æ—¥ä»˜ã‚’è¿½åŠ 
        for record in records:
            record['file_date'] = file_date
            record['source_file'] = filename
        
        all_results.extend(records)
        
        # é€²æ—è¡¨ç¤ºï¼ˆ100ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ï¼‰
        if i % 100 == 0:
            print(f"  â†’ é€²æ—: {i}/{len(kyi_files)} ({i/len(kyi_files)*100:.1f}%)")
            print(f"  â†’ ç´¯è¨ˆãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(all_results):,}")
    
    # JSONä¿å­˜
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… å®Œäº†: {len(all_results):,}ä»¶ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ {output_file} ã«ä¿å­˜")
    
    # ã‚µãƒãƒªãƒ¼
    print("\nğŸ“Š ã‚µãƒãƒªãƒ¼:")
    print(f"  - å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(kyi_files)}")
    print(f"  - æŠ½å‡ºãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(all_results):,}")
    print(f"  - æœŸé–“: {min(r['file_date'] for r in all_results)} ï½ {max(r['file_date'] for r in all_results)}")
    
    return all_results

# å®Ÿè¡Œ
if __name__ == '__main__':
    data_dir = r'C:\JRDB\unzipped'
    output_file = 'kyi_hoof_data_all.json'
    
    results = batch_process_kyi(data_dir, output_file)
```

**å‡ºåŠ›**:
```json
[
  {
    "race_key": "06140105",
    "horse_number": 1,
    "hoof_code": "18",
    "line_number": 1,
    "file_date": "2014-01-05",
    "source_file": "KYI140105.txt"
  },
  ...
]
```

**æƒ³å®šãƒ¬ã‚³ãƒ¼ãƒ‰æ•°**: ç´„400,000ï½500,000ä»¶ï¼ˆ1,265ãƒ•ã‚¡ã‚¤ãƒ« Ã— å¹³å‡350ãƒ¬ã‚³ãƒ¼ãƒ‰/ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰

---

### Phase 4A-3: ZKBè¹„ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¹ã‚¯ãƒªãƒ—ãƒˆä½œæˆ

**ç›®çš„**: å…¨1,265ä»¶ã®ZKBãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¹„é‰„ãƒ»è¹„çŠ¶æ…‹ã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡º

**å…¥åŠ›**:
```
C:\JRDB\unzipped\ZKB*.txtï¼ˆ1,265ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
```

**å‡¦ç†**:
```python
def parse_zkb_hoof_data(file_path):
    """
    ZKBãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¹„é‰„ãƒ»è¹„çŠ¶æ…‹ã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡º
    
    ä»•æ§˜:
    - ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°: Shift_JIS
    - å›ºå®šé•·: 304ãƒã‚¤ãƒˆ/ãƒ¬ã‚³ãƒ¼ãƒ‰
    - è¹„é‰„ã‚³ãƒ¼ãƒ‰: 280-282ãƒã‚¤ãƒˆç›®ï¼ˆ0èµ·ç‚¹: 279-281ï¼‰
    - è¹„çŠ¶æ…‹ã‚³ãƒ¼ãƒ‰: 283-285ãƒã‚¤ãƒˆç›®ï¼ˆ0èµ·ç‚¹: 282-284ï¼‰
    """
    results = []
    
    with open(file_path, 'r', encoding='shift_jis', errors='ignore') as f:
        for line_num, line in enumerate(f, 1):
            try:
                line_bytes = line.encode('shift_jis')
                
                # ãƒ¬ãƒ¼ã‚¹ã‚­ãƒ¼ï¼ˆ1-8ãƒã‚¤ãƒˆç›®ï¼‰
                race_key = line_bytes[0:8].decode('shift_jis').strip()
                
                # é¦¬ç•ªï¼ˆ9-10ãƒã‚¤ãƒˆç›®ï¼‰
                horse_number = line_bytes[8:10].decode('shift_jis').strip()
                
                # è¹„é‰„ã‚³ãƒ¼ãƒ‰ï¼ˆ280-282ãƒã‚¤ãƒˆç›®ã€0èµ·ç‚¹: 279-281ï¼‰
                hoof_iron_code = line_bytes[279:282].decode('shift_jis').strip()
                
                # è¹„çŠ¶æ…‹ã‚³ãƒ¼ãƒ‰ï¼ˆ283-285ãƒã‚¤ãƒˆç›®ã€0èµ·ç‚¹: 282-284ï¼‰
                hoof_condition_code = line_bytes[282:285].decode('shift_jis').strip()
                
                # ç©ºç™½ã‚„NULLå€¤ã‚’ã‚¹ã‚­ãƒƒãƒ—
                if hoof_iron_code or hoof_condition_code:
                    results.append({
                        'race_key': race_key,
                        'horse_number': int(horse_number) if horse_number.isdigit() else None,
                        'hoof_iron_code': hoof_iron_code if hoof_iron_code else None,
                        'hoof_condition_code': hoof_condition_code if hoof_condition_code else None,
                        'line_number': line_num
                    })
                    
            except Exception as e:
                print(f"è­¦å‘Š: {file_path} è¡Œ{line_num}: {str(e)}")
                continue
    
    return results

def batch_process_zkb(data_dir, output_file):
    """
    å…¨ZKBãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬å‡¦ç†
    """
    import glob
    
    all_results = []
    file_pattern = os.path.join(data_dir, 'ZKB*.txt')
    zkb_files = sorted(glob.glob(file_pattern))
    
    print(f"ZKBãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(zkb_files)}")
    
    for i, zkb_file in enumerate(zkb_files, 1):
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ—¥ä»˜ã‚’æŠ½å‡º
        filename = os.path.basename(zkb_file)
        date_str = filename[3:9]
        year = int('20' + date_str[0:2])
        month = int(date_str[2:4])
        day = int(date_str[4:6])
        file_date = f"{year:04d}-{month:02d}-{day:02d}"
        
        print(f"[{i}/{len(zkb_files)}] å‡¦ç†ä¸­: {filename} ({file_date})")
        
        records = parse_zkb_hoof_data(zkb_file)
        
        for record in records:
            record['file_date'] = file_date
            record['source_file'] = filename
        
        all_results.extend(records)
        
        if i % 100 == 0:
            print(f"  â†’ é€²æ—: {i}/{len(zkb_files)} ({i/len(zkb_files)*100:.1f}%)")
            print(f"  â†’ ç´¯è¨ˆãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(all_results):,}")
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… å®Œäº†: {len(all_results):,}ä»¶ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ {output_file} ã«ä¿å­˜")
    
    print("\nğŸ“Š ã‚µãƒãƒªãƒ¼:")
    print(f"  - å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(zkb_files)}")
    print(f"  - æŠ½å‡ºãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(all_results):,}")
    print(f"  - æœŸé–“: {min(r['file_date'] for r in all_results)} ï½ {max(r['file_date'] for r in all_results)}")
    
    return all_results

# å®Ÿè¡Œ
if __name__ == '__main__':
    data_dir = r'C:\JRDB\unzipped'
    output_file = 'zkb_hoof_data_all.json'
    
    results = batch_process_zkb(data_dir, output_file)
```

**æƒ³å®šãƒ¬ã‚³ãƒ¼ãƒ‰æ•°**: ç´„400,000ï½500,000ä»¶

---

### Phase 4A-4: å…¨14ç¨®é¡ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ãƒ¼ã‚µãƒ¼ä½œæˆ

**å„ªå…ˆåº¦**: ä¸­ï¼ˆPhase 5ã§å®Ÿè£…ï¼‰

**å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«**:
1. KYIï¼ˆé¦¬ãƒ‡ãƒ¼ã‚¿ï¼‰â† Phase 4A-2ã§å®Ÿè£…
2. ZKBï¼ˆæˆç¸¾æ‹¡å¼µï¼‰â† Phase 4A-3ã§å®Ÿè£…
3. CYBï¼ˆèª¿æ•™ãƒ‡ãƒ¼ã‚¿ï¼‰
4. ZEDï¼ˆãƒ¬ãƒ¼ã‚¹åŸºæœ¬æƒ…å ±ï¼‰
5. BACï¼ˆé¦¬åŸºæœ¬æƒ…å ±ï¼‰
6. CHAï¼ˆèª¿æ•™å¸«ãƒ‡ãƒ¼ã‚¿ï¼‰
7. JOAï¼ˆé¨æ‰‹ãƒ‡ãƒ¼ã‚¿ï¼‰
8. KABï¼ˆé–‹å‚¬å ´æƒ…å ±ï¼‰
9. KKAï¼ˆé¦¬åŸºæœ¬æƒ…å ±ï¼‰
10. UKCï¼ˆé¦¬æˆç¸¾ï¼‰
11. OTï¼ˆå˜å‹ã‚ªãƒƒã‚ºï¼‰
12. OUï¼ˆè¤‡å‹ã‚ªãƒƒã‚ºï¼‰
13. OWï¼ˆãƒ¯ã‚¤ãƒ‰ã‚ªãƒƒã‚ºï¼‰
14. OZï¼ˆé¦¬é€£ã‚ªãƒƒã‚ºï¼‰

---

### Phase 4A-5: PostgreSQLå…¨ãƒ†ãƒ¼ãƒ–ãƒ«è¨­è¨ˆ

**hoof_data ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆæ—¢ã«è¨­è¨ˆæ¸ˆã¿ï¼‰**:
```sql
CREATE TABLE hoof_data (
    id SERIAL PRIMARY KEY,
    race_key VARCHAR(16) NOT NULL,
    horse_number INTEGER NOT NULL,
    kyi_hoof_code VARCHAR(2),
    zkb_hoof_iron_code VARCHAR(3),
    zkb_hoof_condition_code VARCHAR(3),
    data_source VARCHAR(10) NOT NULL,
    file_date DATE NOT NULL,
    source_file VARCHAR(50),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    CONSTRAINT uq_hoof_data UNIQUE (race_key, horse_number, file_date)
);

CREATE INDEX idx_hoof_data_race_key ON hoof_data(race_key);
CREATE INDEX idx_hoof_data_file_date ON hoof_data(file_date);
```

**ä»–ã®ãƒ†ãƒ¼ãƒ–ãƒ«**ï¼ˆPhase 5ã§è¨­è¨ˆï¼‰:
- kyi_dataï¼ˆ252ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼‰
- zkb_data
- cyb_data
- zed_data
- bac_data
- cha_data
- joa_data
- kab_data
- kka_data
- ukc_data
- odds_dataï¼ˆOT/OU/OW/OZçµ±åˆï¼‰

---

### Phase 4A-6: ãƒãƒƒãƒæŠ•å…¥ã‚¹ã‚¯ãƒªãƒ—ãƒˆä½œæˆ

**ç›®çš„**: JSON â†’ PostgreSQL ä¸€æ‹¬æŠ•å…¥

```python
import pandas as pd
from sqlalchemy import create_engine
import json

def import_hoof_data_to_postgres(kyi_json, zkb_json, db_url):
    """
    KYI + ZKB ã®è¹„ãƒ‡ãƒ¼ã‚¿ã‚’PostgreSQLã«æŠ•å…¥
    """
    # JSONã‚’èª­ã¿è¾¼ã¿
    with open(kyi_json, 'r', encoding='utf-8') as f:
        kyi_data = json.load(f)
    
    with open(zkb_json, 'r', encoding='utf-8') as f:
        zkb_data = json.load(f)
    
    print(f"KYIãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(kyi_data):,}")
    print(f"ZKBãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(zkb_data):,}")
    
    # DataFrameã«å¤‰æ›
    df_kyi = pd.DataFrame(kyi_data)
    df_zkb = pd.DataFrame(zkb_data)
    
    # KYI: data_sourceè¿½åŠ 
    df_kyi['data_source'] = 'KYI'
    df_kyi = df_kyi.rename(columns={'hoof_code': 'kyi_hoof_code'})
    
    # ZKB: data_sourceè¿½åŠ 
    df_zkb['data_source'] = 'ZKB'
    
    # ãƒãƒ¼ã‚¸ï¼ˆFULL OUTER JOINï¼‰
    df_merged = pd.merge(
        df_kyi[['race_key', 'horse_number', 'kyi_hoof_code', 'file_date', 'source_file']],
        df_zkb[['race_key', 'horse_number', 'hoof_iron_code', 'hoof_condition_code']],
        on=['race_key', 'horse_number'],
        how='outer'
    )
    
    # data_sourceæ±ºå®šï¼ˆä¸¡æ–¹ã‚ã‚‹å ´åˆã¯'BOTH'ï¼‰
    df_merged['data_source'] = 'BOTH'
    df_merged.loc[df_merged['kyi_hoof_code'].isna(), 'data_source'] = 'ZKB'
    df_merged.loc[df_merged['hoof_iron_code'].isna(), 'data_source'] = 'KYI'
    
    print(f"\nãƒãƒ¼ã‚¸å¾Œãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(df_merged):,}")
    print(f"KYIã®ã¿: {len(df_merged[df_merged['data_source']=='KYI']):,}")
    print(f"ZKBã®ã¿: {len(df_merged[df_merged['data_source']=='ZKB']):,}")
    print(f"ä¸¡æ–¹: {len(df_merged[df_merged['data_source']=='BOTH']):,}")
    
    # PostgreSQLã«æŠ•å…¥
    engine = create_engine(db_url)
    
    print("\nPostgreSQLã«æŠ•å…¥ä¸­...")
    df_merged.to_sql('hoof_data', engine, if_exists='append', index=False, method='multi', chunksize=10000)
    
    print("âœ… å®Œäº†ï¼")
    
    # æ¤œè¨¼ã‚¯ã‚¨ãƒª
    print("\nğŸ“Š ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼:")
    with engine.connect() as conn:
        result = conn.execute("""
            SELECT 
                COUNT(*) as total_records,
                COUNT(DISTINCT race_key) as total_races,
                COUNT(DISTINCT file_date) as total_days,
                MIN(file_date) as earliest_date,
                MAX(file_date) as latest_date
            FROM hoof_data
        """)
        row = result.fetchone()
        print(f"  - ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {row[0]:,}")
        print(f"  - ãƒ¬ãƒ¼ã‚¹æ•°: {row[1]:,}")
        print(f"  - æ—¥æ•°: {row[2]:,}")
        print(f"  - æœŸé–“: {row[3]} ï½ {row[4]}")

# å®Ÿè¡Œ
if __name__ == '__main__':
    kyi_json = 'kyi_hoof_data_all.json'
    zkb_json = 'zkb_hoof_data_all.json'
    db_url = 'postgresql://user:password@localhost:5432/umayomi'
    
    import_hoof_data_to_postgres(kyi_json, zkb_json, db_url)
```

---

### Phase 4A-7: ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã¨ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ

**æ¤œè¨¼SQL**:
```sql
-- åŸºæœ¬çµ±è¨ˆ
SELECT 
    COUNT(*) as total_records,
    COUNT(DISTINCT race_key) as total_races,
    COUNT(DISTINCT file_date) as total_days,
    MIN(file_date) as earliest_date,
    MAX(file_date) as latest_date,
    COUNT(kyi_hoof_code) as kyi_records,
    COUNT(zkb_hoof_iron_code) as zkb_records
FROM hoof_data;

-- è¹„ã‚³ãƒ¼ãƒ‰åˆ†å¸ƒï¼ˆKYIï¼‰
SELECT 
    kyi_hoof_code,
    COUNT(*) as count,
    ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 2) as percentage
FROM hoof_data
WHERE kyi_hoof_code IS NOT NULL
GROUP BY kyi_hoof_code
ORDER BY count DESC
LIMIT 20;

-- å¹´åº¦åˆ¥ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°
SELECT 
    EXTRACT(YEAR FROM file_date) as year,
    COUNT(*) as record_count,
    COUNT(DISTINCT race_key) as race_count
FROM hoof_data
GROUP BY EXTRACT(YEAR FROM file_date)
ORDER BY year;

-- NULLå€¤åˆ†æ
SELECT 
    'kyi_hoof_code' as field,
    COUNT(*) - COUNT(kyi_hoof_code) as null_count,
    ROUND((COUNT(*) - COUNT(kyi_hoof_code)) * 100.0 / COUNT(*), 2) as null_rate
FROM hoof_data
UNION ALL
SELECT 
    'zkb_hoof_iron_code' as field,
    COUNT(*) - COUNT(zkb_hoof_iron_code) as null_count,
    ROUND((COUNT(*) - COUNT(zkb_hoof_iron_code)) * 100.0 / COUNT(*), 2) as null_rate
FROM hoof_data;
```

---

## ğŸ“Š äºˆæƒ³ã•ã‚Œã‚‹æˆæœç‰©

### ãƒ‡ãƒ¼ã‚¿é‡
- **ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°**: ç´„400,000ï½500,000ä»¶
- **æœŸé–“**: 2014-01-05 ï½ 2025-08-24ï¼ˆ11å¹´8ãƒ¶æœˆï¼‰
- **ãƒ¬ãƒ¼ã‚¹æ•°**: ç´„50,000ãƒ¬ãƒ¼ã‚¹
- **æ—¥æ•°**: ç´„1,265æ—¥

### ãƒ•ã‚¡ã‚¤ãƒ«
1. `kyi_hoof_data_all.json` - KYIè¹„ã‚³ãƒ¼ãƒ‰ï¼ˆç´„450,000ãƒ¬ã‚³ãƒ¼ãƒ‰ï¼‰
2. `zkb_hoof_data_all.json` - ZKBè¹„ãƒ‡ãƒ¼ã‚¿ï¼ˆç´„450,000ãƒ¬ã‚³ãƒ¼ãƒ‰ï¼‰
3. PostgreSQL `hoof_data` ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆç´„500,000ãƒ¬ã‚³ãƒ¼ãƒ‰ï¼‰

---

## â±ï¸ äºˆæƒ³æ‰€è¦æ™‚é–“

| ã‚¿ã‚¹ã‚¯ | æ‰€è¦æ™‚é–“ | æ‹…å½“ |
|--------|---------|------|
| Phase 4A-2: KYIè¹„ã‚³ãƒ¼ãƒ‰æŠ½å‡º | 15-20åˆ† | Python |
| Phase 4A-3: ZKBè¹„ãƒ‡ãƒ¼ã‚¿æŠ½å‡º | 15-20åˆ† | Python |
| Phase 4A-6: PostgreSQLæŠ•å…¥ | 10-15åˆ† | Python |
| Phase 4A-7: ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ | 5åˆ† | SQL |
| **åˆè¨ˆ** | **45-60åˆ†** | - |

---

## ğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆPhase 5ï¼‰

**Phase 5: å…¨14ç¨®é¡ãƒ•ã‚¡ã‚¤ãƒ«ã®å®Œå…¨å–ã‚Šè¾¼ã¿**

1. æ®‹ã‚Š12ç¨®é¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ãƒ¼ã‚µãƒ¼ä½œæˆ
2. 252ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å®Œå…¨PostgreSQLæ ¼ç´
3. ãƒ‡ãƒ¼ã‚¿é–¢é€£ä»˜ã‘ï¼ˆãƒ¬ãƒ¼ã‚¹ã‚­ãƒ¼ã§JOINï¼‰
4. ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ä½œæˆUIå®Ÿè£…æº–å‚™

---

**UMAYOMI - é¦¬ã‚’èª­ã‚€ã€‚ãƒ¬ãƒ¼ã‚¹ãŒå¤‰ã‚ã‚‹ã€‚**

ã“ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã—ã¦ã€Phase 4Aï¼ˆJRDBãƒ‡ãƒ¼ã‚¿çµ±åˆå®Ÿè£…ï¼‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

---

**å®Ÿè¡Œç’°å¢ƒ**:
- Windows 11 (CEOã®ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒ)
- Python 3.x
- PostgreSQL 13+
- pandas, SQLAlchemy

**ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹**:
- `C:\JRDB\unzipped\`
- 18,974ãƒ•ã‚¡ã‚¤ãƒ«
- 3.87 GB
- Shift_JIS ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°

**ç›®æ¨™**:
- è¹„ãƒ‡ãƒ¼ã‚¿ï¼ˆKYI + ZKBï¼‰ã‚’ PostgreSQL ã«å®Œå…¨æ ¼ç´
- ç´„500,000ãƒ¬ã‚³ãƒ¼ãƒ‰
- 11å¹´8ãƒ¶æœˆã®ãƒ‡ãƒ¼ã‚¿
